{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42436f92-6fa0-4d7d-9b3f-896f6f16b440",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# About\n",
    "Here, I build a Q&A LLM chain to read the book \"Time Machine\" and answer questions about the book. \n",
    "\n",
    "The LLM model I ued is Meta's `llama2 7B` model (Ollma ID `78e26419b446`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7182dcc-1c52-44de-9d34-69b1ec7dc797",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe946c2d-86fb-4368-a261-01729a849bc5",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dab4ebc5-60a5-4720-856b-535e1281ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain related \n",
    "from langchain import PromptTemplate\n",
    "from langchain.document_loaders import GutenbergLoader\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "\n",
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# put Huggingface API token in an py file (..config/token_access.py) and load it\n",
    "from config import token_access\n",
    "\n",
    "# set HUGGINGFACEHUB_API_TOKEN to my token_access\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = token_access.token_access\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a468c0e7-b814-4deb-8624-b3f12e12de94",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27aa3e5-9786-4705-9dfc-236c9d9c8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuppressStdout:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        self._original_stderr = sys.stderr\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        sys.stderr = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "        sys.stderr = self._original_stderr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da87e639-dad9-4d37-8799-dfe41e4d936c",
   "metadata": {},
   "source": [
    "### Variables that require changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0f813-61db-46fc-aa45-be6283e745c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------#\n",
    "# data related\n",
    "#----------------#\n",
    "# a variable name used to define specific path\n",
    "author=\"HGWells\"\n",
    "\n",
    "# book txt file link\n",
    "book_link =\"https://www.gutenberg.org/cache/epub/35/pg35.txt\"\n",
    "\n",
    "#----------------#\n",
    "# model related\n",
    "#----------------#\n",
    "#  embeddings\n",
    "embeddings_model_id =\"huggingface_embeddings\"\n",
    "\n",
    "# llm model used for reading the book\n",
    "llm_model_id =\"llama2\"\n",
    "\n",
    "#----------------#\n",
    "# your project root path \n",
    "#----------------#\n",
    "main_Dir = \"../book-reader\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c5154b-7d49-4556-9456-96acf3bf39ab",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb2aa707-2ea0-4fac-aba6-6fa839309e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------#\n",
    "# data dir\n",
    "#----------------#\n",
    "data_Dir = os.path.join(main_Dir,\"data\")\n",
    "\n",
    "# embeddings dir\n",
    "embedding_string= f\"{embeddings_model_id}\".replace(\"/\", \"_\").replace(\"-\",\"_\")\n",
    "\n",
    "# hugging face llm pipeline model dir\n",
    "embedding_Dir = os.path.join(data_Dir,f\"{author}_{embedding_string}\")\n",
    "\n",
    "#----------------#\n",
    "# model dir\n",
    "#----------------#\n",
    "model_Dir= os.path.join(main_Dir,\"model\")\n",
    "cache_Dir = os.path.join(model_Dir,\"cache\")\n",
    "\n",
    "\n",
    "#----------------#\n",
    "# make dirs\n",
    "#----------------#\n",
    "for f in [data_Dir, embedding_Dir , model_Dir, cache_Dir]:\n",
    "    os.makedirs(f, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb27b6d-2ffa-44c9-9613-b180fbb0b8d7",
   "metadata": {},
   "source": [
    "# Read a book \n",
    "### \"The Time Machine by H. G. Wells\" from Gutenberg Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6025c336-a6e6-4824-9e4b-c02cce984743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the book \n",
    "book_loader = GutenbergLoader(book_link)  \n",
    "\n",
    "document = book_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae86cd9-130f-4302-ac66-319e6e6f2249",
   "metadata": {},
   "source": [
    "## Creating a QA LLM Chain\n",
    "This chain will be used to do QA on the document. We will need\n",
    " * A vector database that can perform document retrieval\n",
    " * An LLM to do the language interpretation\n",
    " * Specification on how to deal with this data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b31468-9abb-44e2-a1d7-3b6cc3d50d65",
   "metadata": {},
   "source": [
    "### A vector database that can perform document retrieval\n",
    " * split data into chunks\n",
    " * use Hugging Face's embedding LLM to embed this data for our vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31885db6-b3a0-481d-a611-4626f1eb68ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.json: 100%|█████████████████████████████████████████████████████████████| 349/349 [00:00<00:00, 30.9kB/s]\n",
      "config_sentence_transformers.json: 100%|████████████████████████████████████████| 116/116 [00:00<00:00, 34.5kB/s]\n",
      "README.md: 100%|████████████████████████████████████████████████████████████| 10.6k/10.6k [00:00<00:00, 3.22MB/s]\n",
      "sentence_bert_config.json: 100%|██████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 12.3kB/s]\n",
      "config.json: 100%|███████████████████████████████████████████████████████████████| 571/571 [00:00<00:00, 232kB/s]\n",
      "pytorch_model.bin: 100%|██████████████████████████████████████████████████████| 438M/438M [01:36<00:00, 4.55MB/s]\n",
      "tokenizer_config.json: 100%|████████████████████████████████████████████████████| 363/363 [00:00<00:00, 10.8kB/s]\n",
      "vocab.txt: 100%|██████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 1.18MB/s]\n",
      "tokenizer.json: 100%|█████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 1.68MB/s]\n",
      "special_tokens_map.json: 100%|██████████████████████████████████████████████████| 239/239 [00:00<00:00, 85.8kB/s]\n",
      "1_Pooling/config.json: 100%|████████████████████████████████████████████████████| 190/190 [00:00<00:00, 16.3kB/s]\n"
     ]
    }
   ],
   "source": [
    "# chunk sizes\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(document)\n",
    "\n",
    "# create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "  cache_folder=embedding_Dir\n",
    ")\n",
    "\n",
    "# Make Index using chromadb and the embeddings LLM\n",
    "with SuppressStdout():   \n",
    "    chromadb_index = Chroma.from_documents(documents=texts, embedding=embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b088e2a-e642-44e3-a7c7-c11117ed2300",
   "metadata": {},
   "source": [
    "### An LLM which does interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "daa307b8-9445-4d18-b4b4-8a090ff227a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Ollama \n",
    "hf_llm = Ollama(model=llm_model_id, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b8dfc-4b5a-4755-9f6e-d10778c84f06",
   "metadata": {},
   "source": [
    "### Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02d4adb6-316f-4bbd-a927-ba95889aaee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc592dc7-3230-4aad-9dd6-cdc707317ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to retriever (A wrapper around the functionality of our vector database so we can search for similar documents/chunks in the vectorstore and retrieve the results)\n",
    "retriever = chromadb_index.as_retriever()\n",
    "\n",
    "# qa retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    hf_llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb9f8f2-b1fa-439c-9f56-97ce218a4bff",
   "metadata": {},
   "source": [
    "# Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc3e57a-ecbd-4b1d-bb2d-37fd8fed711f",
   "metadata": {},
   "source": [
    "### Did ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9f80a56-fb2f-49dc-a251-3d8569c3fe80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book was written by H.G. Wells."
     ]
    }
   ],
   "source": [
    "question = \"Who wrote this book?\"\n",
    "answer = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b66163e-0742-4872-9fed-431eca1d3b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author of The Time Machine is H.G. Wells."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Who is the author of Time Machine?',\n",
       " 'result': 'The author of The Time Machine is H.G. Wells.'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Who is the author of Time Machine?\"\n",
    "answer = qa_chain({\"query\": question})\n",
    "display(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60fce8d2-f822-4457-980b-99396226dd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text does not provide a clear description of how the Eloi look like. However, it is mentioned that they are \"mere fatted cattle\" and \"disgusting\" to the Morlocks, which suggests that they may be weak and vulnerable compared to their more robust and intelligent creators. The text also notes that the Eloi have retained some human form, but it is not clear what this means in terms of their physical appearance. Overall, the Eloi are portrayed as being inferior to the Morlocks in both physical strength and intelligence."
     ]
    }
   ],
   "source": [
    "question = \"How do Eloi look like?\"\n",
    "answer = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21894aac-d79f-47fc-8f43-f6896c185efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morlocks are described as \"pallid bodies\" with \"battered\" faces and \"reddish\" backs. They are also said to be \"subterranean for innumerable generations,\" suggesting that they have evolved to live underground."
     ]
    }
   ],
   "source": [
    "question = \"How do Morlock look like?\"\n",
    "answer = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c147d856-52df-4135-950c-3beffec15aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fourth dimension in the novella \"The Time Machine\" is a hypothetical direction perpendicular to the three dimensions of space that we are familiar with. According to the Time Traveller, consciousness moves intermittently in one direction along this fourth dimension from the beginning to the end of our lives. Some philosophical people have been asking why three dimensions particularly and have even tried to construct a Four-Dimensional geometry, but the Time Traveller believes that there is no difference between time and any of the three dimensions of space except for our consciousness moving along it."
     ]
    }
   ],
   "source": [
    "question = \"In this novella, what is the fourth dimension?\"\n",
    "answer = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fbf35dc-1ef5-499d-90b4-287179a9c6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Morlocks are temporarily blinds by the glare of the fire."
     ]
    }
   ],
   "source": [
    "question = \"What temporarily blinds the Morlocks?\"\n",
    "answer = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad96fb45-c86e-4bac-8230-0bcc34e068aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filby is an argumentative person with red hair."
     ]
    }
   ],
   "source": [
    "question = \"Who is Filby?\"\n",
    "answer = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "683a1bc6-28cf-4577-9573-300a1cbe1a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scientific principle that the Time Traveler's visit to the decaying world thirty millions in the future illustrates is the concept of causality. The idea that events in the past can have a significant impact on the present, and that the actions of beings in the past can shape the course of events in the future. The Time Traveller's journey through time demonstrates how events that occurred in the past can have a lasting impact on the present, even after millions of years have passed."
     ]
    }
   ],
   "source": [
    "question = \"What scientific principle does the Time Traveler's visit to the decaying world thirty millions in the future illustrate?\"\n",
    "answer = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8ac4c93-0cdf-498d-8cf5-4d417df465a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Time Machine is held inside a pedestal."
     ]
    }
   ],
   "source": [
    "question = \"Where is the Time Machine held?\"\n",
    "answer = qa_chain({\"query\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4139f9d5-0703-48e0-b804-430dfde83751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eloi eat fruit."
     ]
    }
   ],
   "source": [
    "question = \"What do the Eloi eat?\"\n",
    "answer = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbe23e90-b563-4f57-af5b-7b398ce48b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inventor of the time machine in the novella is the Time Traveller."
     ]
    }
   ],
   "source": [
    "question = \"Who was the inventor of time machine in the novella?\"\n",
    "answer = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e763ff6b-1e36-46cd-8252-023ae5085f5d",
   "metadata": {},
   "source": [
    "### Did not do well (Did not ask properly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdbaccb8-00bb-4d4e-a669-e0539e0b5226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Time Machine was invented by H.G. Wells."
     ]
    }
   ],
   "source": [
    "question = \"Who invented the Time Machine?\"\n",
    "answer = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c05e89b9-c7c4-405b-af8d-08030ac3652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the Time Traveller in the novella is \"The Time Traveller.\""
     ]
    }
   ],
   "source": [
    "question = \"What is the name of the Time Traveller in the novella?\"\n",
    "answer = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e65a3a-05b1-409d-bec0-53659e7366a1",
   "metadata": {},
   "source": [
    "# Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9610470d-163f-4503-9a6a-b08250ba652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save hugging face llm pipeline\n",
    "hf_llm_string= f\"{llm_model_id}\".replace(\"/\", \"_\").replace(\"-\",\"_\")\n",
    "\n",
    "# hugging face llm pipeline model dir\n",
    "hf_llm_Dir = os.path.join(model_Dir,f\"{author}_{hf_llm_string}\")\n",
    "\n",
    "# create dir if not existing \n",
    "for f in [hf_llm_Dir]:\n",
    "    os.makedirs(f, exist_ok=True)\n",
    "\n",
    "\n",
    "# save huggingface pipeline \n",
    "hf_llm.save(os.path.join(hf_llm_Dir,f\"{hf_llm_string}.json\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
